# Titanic Survival Predictions ğŸš¢âœ¨

## Project Overview
Embark on a data-driven journey into the historical voyage of the Titanic with our Titanic Survival Predictions project. This initiative involves predicting passenger survival using state-of-the-art binary classification algorithms.

## Implemented Algorithms
Our project delves into the power of various binary classification algorithms, each contributing a unique perspective to predicting survival outcomes. The algorithms include:

1. Decision Tree Classifier ğŸŒ³
2. Logistic Regression ğŸ“ˆ
3. Random Forest Classifier ğŸŒ²
4. Naive Bayes (GaussianNB) ğŸ“Š
5. XGBoost Classifier ğŸš€
6. CatBoost Classifier ğŸ±

## Visualization ğŸ“Š
Visualizing the performance of these algorithms is crucial for understanding their effectiveness. We've employed Matplotlib to create insightful plots and charts, providing a visually appealing and intuitive representation of each algorithm's predictions.

## Data Preprocessing ğŸ› ï¸
To ensure the accuracy of our models, we've employed Pandas and Scikit-learn for comprehensive data preprocessing. This includes handling missing values, encoding categorical variables, and preparing the data for the model training process.

1. **Handling Missing Values with SimpleImputer ğŸ”„**:
We addressed missing data using SimpleImputer to maintain the integrity of our dataset.

2. **OneHotEncoding for Categorical Variables ğŸ§®**:
Categorical variables were encoded using OneHotEncoding to enable their incorporation into the models.

3. **Feature Scaling with StandardScaler ğŸ“**:
Feature scaling using StandardScaler was applied to ensure uniformity and optimize model training.

## Automation with Pipelines ğŸš€
Our workflow is optimized for efficiency through the implementation of Scikit-learn pipelines. These pipelines automate the end-to-end process, organizing data processing and model training steps seamlessly.

## Best Performing Algorithm ğŸ†
After rigorous evaluation, the CatBoost Classifier emerged as the star performer in predicting Titanic survival. Its robust capabilities set it apart from the rest, making it the algorithm of choice for this project.

## Feature Scaling and Precision Boost ğŸ“
To further elevate our model's precision, we applied feature scaling using the StandardScaler function. This strategic step significantly increased precision scores, refining the accuracy of our survival predictions.

## Project Resources ğŸ“
Dataset: [Kaggle Dataset](https://www.kaggle.com/competitions/titanic)

Notebooks Folder:[Titanic Survival Predictions](https://colab.research.google.com/drive/1qAFbgP07crFNvemKBMxLH0m6iFL2Z5gF#scrollTo=GBliFtBZpOjL)

Join us in this exploration of data, algorithms, and the fascinating story of Titanic survival. Contribute, learn, and witness the magic of predictive analytics unfold! âš“ï¸ğŸ”®
## Team Profiles
* Member 1: [XenoWing](https://www.kaggle.com/xenowing)
