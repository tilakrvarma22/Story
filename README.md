# Titanic Survival Predictions 🚢✨

## Project Overview
Embark on a data-driven journey into the historical voyage of the Titanic with our Titanic Survival Predictions project. This initiative involves predicting passenger survival using state-of-the-art binary classification algorithms.

## Implemented Algorithms
Our project delves into the power of various binary classification algorithms, each contributing a unique perspective to predicting survival outcomes. The algorithms include:

1. Decision Tree Classifier 🌳
2. Logistic Regression 📈
3. Random Forest Classifier 🌲
4. Naive Bayes (GaussianNB) 📊
5. XGBoost Classifier 🚀
6. CatBoost Classifier 🐱

## Visualization 📊
Visualizing the performance of these algorithms is crucial for understanding their effectiveness. We've employed Matplotlib to create insightful plots and charts, providing a visually appealing and intuitive representation of each algorithm's predictions.

## Data Preprocessing 🛠️
To ensure the accuracy of our models, we've employed Pandas and Scikit-learn for comprehensive data preprocessing. This includes handling missing values, encoding categorical variables, and preparing the data for the model training process.

1. **Handling Missing Values with SimpleImputer 🔄**:
We addressed missing data using SimpleImputer to maintain the integrity of our dataset.

2. **OneHotEncoding for Categorical Variables 🧮**:
Categorical variables were encoded using OneHotEncoding to enable their incorporation into the models.

3. **Feature Scaling with StandardScaler 📏**:
Feature scaling using StandardScaler was applied to ensure uniformity and optimize model training.

## Automation with Pipelines 🚀
Our workflow is optimized for efficiency through the implementation of Scikit-learn pipelines. These pipelines automate the end-to-end process, organizing data processing and model training steps seamlessly.

## Best Performing Algorithm 🏆
After rigorous evaluation, the CatBoost Classifier emerged as the star performer in predicting Titanic survival. Its robust capabilities set it apart from the rest, making it the algorithm of choice for this project.

## Feature Scaling and Precision Boost 📏
To further elevate our model's precision, we applied feature scaling using the StandardScaler function. This strategic step significantly increased precision scores, refining the accuracy of our survival predictions.

## Project Resources 📁
Dataset: [Kaggle Dataset](https://www.kaggle.com/competitions/titanic)

Notebooks Folder:[Titanic Survival Predictions](https://colab.research.google.com/drive/1qAFbgP07crFNvemKBMxLH0m6iFL2Z5gF#scrollTo=GBliFtBZpOjL)

Join us in this exploration of data, algorithms, and the fascinating story of Titanic survival. Contribute, learn, and witness the magic of predictive analytics unfold! ⚓️🔮
## Team Profiles
* Member 1: [XenoWing](https://www.kaggle.com/xenowing)
